{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model the best technique is to actually design small experiment and emperically evaluate option using the real data.\n",
    "\n",
    "The large amount data and the complexity of the model required very long training times so we must simply seperate the data into training, validation and testing datasets.\n",
    "\n",
    "Keras provide the convinent way to do so:\n",
    "\n",
    "1. Automatic verification datsets\n",
    "2. Manual verification datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Datasets\n",
    "\n",
    "data = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the AUTOMATIC VERIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## Creating model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compiling the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/100\n",
      "614/614 [==============================] - 0s 284us/step - loss: 0.6792 - acc: 0.6450 - val_loss: 0.6686 - val_acc: 0.6429\n",
      "Epoch 2/100\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.6647 - acc: 0.6547 - val_loss: 0.6659 - val_acc: 0.6429\n",
      "Epoch 3/100\n",
      "614/614 [==============================] - 0s 129us/step - loss: 0.6529 - acc: 0.6547 - val_loss: 0.6627 - val_acc: 0.6494\n",
      "Epoch 4/100\n",
      "614/614 [==============================] - 0s 131us/step - loss: 0.6437 - acc: 0.6596 - val_loss: 0.6767 - val_acc: 0.6494\n",
      "Epoch 5/100\n",
      "614/614 [==============================] - 0s 134us/step - loss: 0.6371 - acc: 0.6726 - val_loss: 0.6502 - val_acc: 0.6494\n",
      "Epoch 6/100\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.6250 - acc: 0.6694 - val_loss: 0.6455 - val_acc: 0.5974\n",
      "Epoch 7/100\n",
      "614/614 [==============================] - 0s 134us/step - loss: 0.6206 - acc: 0.6678 - val_loss: 0.6207 - val_acc: 0.6818\n",
      "Epoch 8/100\n",
      "614/614 [==============================] - 0s 134us/step - loss: 0.6145 - acc: 0.6694 - val_loss: 0.6301 - val_acc: 0.6623\n",
      "Epoch 9/100\n",
      "614/614 [==============================] - 0s 134us/step - loss: 0.6066 - acc: 0.6792 - val_loss: 0.6071 - val_acc: 0.6558\n",
      "Epoch 10/100\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.6026 - acc: 0.6840 - val_loss: 0.5995 - val_acc: 0.6818\n",
      "Epoch 11/100\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.5997 - acc: 0.7068 - val_loss: 0.5832 - val_acc: 0.6818\n",
      "Epoch 12/100\n",
      "614/614 [==============================] - 0s 135us/step - loss: 0.5910 - acc: 0.6971 - val_loss: 0.5921 - val_acc: 0.6948\n",
      "Epoch 13/100\n",
      "614/614 [==============================] - 0s 151us/step - loss: 0.5907 - acc: 0.7068 - val_loss: 0.5872 - val_acc: 0.6948\n",
      "Epoch 14/100\n",
      "614/614 [==============================] - 0s 171us/step - loss: 0.5849 - acc: 0.7101 - val_loss: 0.5762 - val_acc: 0.6883\n",
      "Epoch 15/100\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.5816 - acc: 0.7166 - val_loss: 0.5818 - val_acc: 0.6948\n",
      "Epoch 16/100\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.5786 - acc: 0.7068 - val_loss: 0.5860 - val_acc: 0.6623\n",
      "Epoch 17/100\n",
      "614/614 [==============================] - 0s 169us/step - loss: 0.5747 - acc: 0.7101 - val_loss: 0.5737 - val_acc: 0.7273\n",
      "Epoch 18/100\n",
      "614/614 [==============================] - 0s 156us/step - loss: 0.5778 - acc: 0.7182 - val_loss: 0.5744 - val_acc: 0.6623\n",
      "Epoch 19/100\n",
      "614/614 [==============================] - 0s 142us/step - loss: 0.5718 - acc: 0.7182 - val_loss: 0.5586 - val_acc: 0.7273\n",
      "Epoch 20/100\n",
      "614/614 [==============================] - 0s 171us/step - loss: 0.5691 - acc: 0.7182 - val_loss: 0.5676 - val_acc: 0.6753\n",
      "Epoch 21/100\n",
      "614/614 [==============================] - 0s 148us/step - loss: 0.5654 - acc: 0.7182 - val_loss: 0.5804 - val_acc: 0.6948\n",
      "Epoch 22/100\n",
      "614/614 [==============================] - 0s 168us/step - loss: 0.5619 - acc: 0.7296 - val_loss: 0.5652 - val_acc: 0.7013\n",
      "Epoch 23/100\n",
      "614/614 [==============================] - 0s 150us/step - loss: 0.5585 - acc: 0.7264 - val_loss: 0.5606 - val_acc: 0.7078\n",
      "Epoch 24/100\n",
      "614/614 [==============================] - 0s 142us/step - loss: 0.5567 - acc: 0.7329 - val_loss: 0.5752 - val_acc: 0.6883\n",
      "Epoch 25/100\n",
      "614/614 [==============================] - 0s 163us/step - loss: 0.5646 - acc: 0.7329 - val_loss: 0.5600 - val_acc: 0.7273\n",
      "Epoch 26/100\n",
      "614/614 [==============================] - 0s 165us/step - loss: 0.5527 - acc: 0.7215 - val_loss: 0.5755 - val_acc: 0.6883\n",
      "Epoch 27/100\n",
      "614/614 [==============================] - 0s 187us/step - loss: 0.5500 - acc: 0.7394 - val_loss: 0.5588 - val_acc: 0.6948\n",
      "Epoch 28/100\n",
      "614/614 [==============================] - 0s 187us/step - loss: 0.5479 - acc: 0.7394 - val_loss: 0.5533 - val_acc: 0.6948\n",
      "Epoch 29/100\n",
      "614/614 [==============================] - 0s 168us/step - loss: 0.5558 - acc: 0.7329 - val_loss: 0.5675 - val_acc: 0.6883\n",
      "Epoch 30/100\n",
      "614/614 [==============================] - 0s 147us/step - loss: 0.5448 - acc: 0.7248 - val_loss: 0.5657 - val_acc: 0.7208\n",
      "Epoch 31/100\n",
      "614/614 [==============================] - 0s 168us/step - loss: 0.5377 - acc: 0.7264 - val_loss: 0.5499 - val_acc: 0.7338\n",
      "Epoch 32/100\n",
      "614/614 [==============================] - 0s 220us/step - loss: 0.5439 - acc: 0.7231 - val_loss: 0.5676 - val_acc: 0.6818\n",
      "Epoch 33/100\n",
      "614/614 [==============================] - 0s 183us/step - loss: 0.5401 - acc: 0.7443 - val_loss: 0.5588 - val_acc: 0.6948\n",
      "Epoch 34/100\n",
      "614/614 [==============================] - 0s 199us/step - loss: 0.5451 - acc: 0.7394 - val_loss: 0.5533 - val_acc: 0.7143\n",
      "Epoch 35/100\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.5349 - acc: 0.7427 - val_loss: 0.5768 - val_acc: 0.6818\n",
      "Epoch 36/100\n",
      "614/614 [==============================] - 0s 139us/step - loss: 0.5325 - acc: 0.7443 - val_loss: 0.5628 - val_acc: 0.7403\n",
      "Epoch 37/100\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.5223 - acc: 0.7524 - val_loss: 0.6204 - val_acc: 0.6818\n",
      "Epoch 38/100\n",
      "614/614 [==============================] - 0s 142us/step - loss: 0.5363 - acc: 0.7296 - val_loss: 0.5621 - val_acc: 0.7078\n",
      "Epoch 39/100\n",
      "614/614 [==============================] - 0s 130us/step - loss: 0.5318 - acc: 0.7329 - val_loss: 0.5700 - val_acc: 0.7532\n",
      "Epoch 40/100\n",
      "614/614 [==============================] - 0s 131us/step - loss: 0.5275 - acc: 0.7410 - val_loss: 0.5661 - val_acc: 0.7597\n",
      "Epoch 41/100\n",
      "614/614 [==============================] - 0s 131us/step - loss: 0.5304 - acc: 0.7378 - val_loss: 0.5474 - val_acc: 0.7532\n",
      "Epoch 42/100\n",
      "614/614 [==============================] - 0s 126us/step - loss: 0.5286 - acc: 0.7508 - val_loss: 0.5612 - val_acc: 0.6883\n",
      "Epoch 43/100\n",
      "614/614 [==============================] - 0s 145us/step - loss: 0.5291 - acc: 0.7378 - val_loss: 0.5681 - val_acc: 0.6883\n",
      "Epoch 44/100\n",
      "614/614 [==============================] - 0s 131us/step - loss: 0.5209 - acc: 0.7329 - val_loss: 0.5494 - val_acc: 0.7208\n",
      "Epoch 45/100\n",
      "614/614 [==============================] - 0s 149us/step - loss: 0.5241 - acc: 0.7329 - val_loss: 0.5560 - val_acc: 0.7078\n",
      "Epoch 46/100\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.5106 - acc: 0.7459 - val_loss: 0.5545 - val_acc: 0.7013\n",
      "Epoch 47/100\n",
      "614/614 [==============================] - 0s 128us/step - loss: 0.5139 - acc: 0.7313 - val_loss: 0.5493 - val_acc: 0.7143\n",
      "Epoch 48/100\n",
      "614/614 [==============================] - 0s 138us/step - loss: 0.5158 - acc: 0.7394 - val_loss: 0.5668 - val_acc: 0.7078\n",
      "Epoch 49/100\n",
      "614/614 [==============================] - 0s 198us/step - loss: 0.5131 - acc: 0.7606 - val_loss: 0.5776 - val_acc: 0.6948\n",
      "Epoch 50/100\n",
      "614/614 [==============================] - 0s 167us/step - loss: 0.5129 - acc: 0.7410 - val_loss: 0.5387 - val_acc: 0.7662\n",
      "Epoch 51/100\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.5126 - acc: 0.7443 - val_loss: 0.5477 - val_acc: 0.7208\n",
      "Epoch 52/100\n",
      "614/614 [==============================] - 0s 137us/step - loss: 0.5201 - acc: 0.7378 - val_loss: 0.5488 - val_acc: 0.7532\n",
      "Epoch 53/100\n",
      "614/614 [==============================] - 0s 134us/step - loss: 0.5106 - acc: 0.7606 - val_loss: 0.5530 - val_acc: 0.7532\n",
      "Epoch 54/100\n",
      "614/614 [==============================] - 0s 130us/step - loss: 0.5071 - acc: 0.7541 - val_loss: 0.5470 - val_acc: 0.7273\n",
      "Epoch 55/100\n",
      "614/614 [==============================] - 0s 139us/step - loss: 0.5058 - acc: 0.7622 - val_loss: 0.5458 - val_acc: 0.7662\n",
      "Epoch 56/100\n",
      "614/614 [==============================] - 0s 151us/step - loss: 0.5097 - acc: 0.7443 - val_loss: 0.5438 - val_acc: 0.7273\n",
      "Epoch 57/100\n",
      "614/614 [==============================] - 0s 176us/step - loss: 0.5080 - acc: 0.7492 - val_loss: 0.5629 - val_acc: 0.7273\n",
      "Epoch 58/100\n",
      "614/614 [==============================] - 0s 180us/step - loss: 0.5032 - acc: 0.7573 - val_loss: 0.5434 - val_acc: 0.7662\n",
      "Epoch 59/100\n",
      "614/614 [==============================] - 0s 160us/step - loss: 0.4981 - acc: 0.7524 - val_loss: 0.5368 - val_acc: 0.7338\n",
      "Epoch 60/100\n",
      "614/614 [==============================] - 0s 151us/step - loss: 0.5103 - acc: 0.7459 - val_loss: 0.5436 - val_acc: 0.7532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "614/614 [==============================] - 0s 134us/step - loss: 0.5076 - acc: 0.7687 - val_loss: 0.5453 - val_acc: 0.7662\n",
      "Epoch 62/100\n",
      "614/614 [==============================] - 0s 121us/step - loss: 0.4970 - acc: 0.7476 - val_loss: 0.5657 - val_acc: 0.7013\n",
      "Epoch 63/100\n",
      "614/614 [==============================] - 0s 131us/step - loss: 0.4989 - acc: 0.7590 - val_loss: 0.5460 - val_acc: 0.7662\n",
      "Epoch 64/100\n",
      "614/614 [==============================] - 0s 146us/step - loss: 0.5037 - acc: 0.7508 - val_loss: 0.5412 - val_acc: 0.7597\n",
      "Epoch 65/100\n",
      "614/614 [==============================] - 0s 168us/step - loss: 0.4935 - acc: 0.7573 - val_loss: 0.5359 - val_acc: 0.7403\n",
      "Epoch 66/100\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.4877 - acc: 0.7590 - val_loss: 0.5397 - val_acc: 0.7792\n",
      "Epoch 67/100\n",
      "614/614 [==============================] - 0s 153us/step - loss: 0.4927 - acc: 0.7476 - val_loss: 0.5363 - val_acc: 0.7338\n",
      "Epoch 68/100\n",
      "614/614 [==============================] - 0s 136us/step - loss: 0.5041 - acc: 0.7443 - val_loss: 0.5427 - val_acc: 0.7403\n",
      "Epoch 69/100\n",
      "614/614 [==============================] - 0s 130us/step - loss: 0.5017 - acc: 0.7622 - val_loss: 0.5503 - val_acc: 0.7143\n",
      "Epoch 70/100\n",
      "614/614 [==============================] - 0s 142us/step - loss: 0.4940 - acc: 0.7655 - val_loss: 0.5612 - val_acc: 0.7143\n",
      "Epoch 71/100\n",
      "614/614 [==============================] - 0s 135us/step - loss: 0.4981 - acc: 0.7590 - val_loss: 0.5370 - val_acc: 0.7273\n",
      "Epoch 72/100\n",
      "614/614 [==============================] - 0s 136us/step - loss: 0.4858 - acc: 0.7752 - val_loss: 0.5377 - val_acc: 0.7338\n",
      "Epoch 73/100\n",
      "614/614 [==============================] - 0s 137us/step - loss: 0.4909 - acc: 0.7704 - val_loss: 0.5359 - val_acc: 0.7338\n",
      "Epoch 74/100\n",
      "614/614 [==============================] - 0s 138us/step - loss: 0.4845 - acc: 0.7524 - val_loss: 0.5342 - val_acc: 0.7468\n",
      "Epoch 75/100\n",
      "614/614 [==============================] - 0s 125us/step - loss: 0.4867 - acc: 0.7687 - val_loss: 0.5318 - val_acc: 0.7468\n",
      "Epoch 76/100\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.4869 - acc: 0.7638 - val_loss: 0.5311 - val_acc: 0.7792\n",
      "Epoch 77/100\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4900 - acc: 0.7590 - val_loss: 0.5364 - val_acc: 0.7143\n",
      "Epoch 78/100\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4878 - acc: 0.7557 - val_loss: 0.5309 - val_acc: 0.7532\n",
      "Epoch 79/100\n",
      "614/614 [==============================] - 0s 123us/step - loss: 0.4853 - acc: 0.7573 - val_loss: 0.5291 - val_acc: 0.7662\n",
      "Epoch 80/100\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.4761 - acc: 0.7638 - val_loss: 0.5531 - val_acc: 0.7273\n",
      "Epoch 81/100\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.4868 - acc: 0.7590 - val_loss: 0.5312 - val_acc: 0.7597\n",
      "Epoch 82/100\n",
      "614/614 [==============================] - 0s 141us/step - loss: 0.4811 - acc: 0.7785 - val_loss: 0.5311 - val_acc: 0.7468\n",
      "Epoch 83/100\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.4850 - acc: 0.7459 - val_loss: 0.5798 - val_acc: 0.7143\n",
      "Epoch 84/100\n",
      "614/614 [==============================] - 0s 146us/step - loss: 0.4864 - acc: 0.7590 - val_loss: 0.5291 - val_acc: 0.7727\n",
      "Epoch 85/100\n",
      "614/614 [==============================] - 0s 144us/step - loss: 0.4796 - acc: 0.7736 - val_loss: 0.5289 - val_acc: 0.7403\n",
      "Epoch 86/100\n",
      "614/614 [==============================] - 0s 134us/step - loss: 0.4823 - acc: 0.7671 - val_loss: 0.5518 - val_acc: 0.7273\n",
      "Epoch 87/100\n",
      "614/614 [==============================] - 0s 137us/step - loss: 0.4857 - acc: 0.7606 - val_loss: 0.5378 - val_acc: 0.7273\n",
      "Epoch 88/100\n",
      "614/614 [==============================] - 0s 126us/step - loss: 0.4992 - acc: 0.7671 - val_loss: 0.5268 - val_acc: 0.7468\n",
      "Epoch 89/100\n",
      "614/614 [==============================] - 0s 139us/step - loss: 0.4744 - acc: 0.7736 - val_loss: 0.5343 - val_acc: 0.7208\n",
      "Epoch 90/100\n",
      "614/614 [==============================] - 0s 131us/step - loss: 0.4774 - acc: 0.7704 - val_loss: 0.5279 - val_acc: 0.7532\n",
      "Epoch 91/100\n",
      "614/614 [==============================] - 0s 134us/step - loss: 0.4878 - acc: 0.7573 - val_loss: 0.5765 - val_acc: 0.7013\n",
      "Epoch 92/100\n",
      "614/614 [==============================] - 0s 122us/step - loss: 0.4815 - acc: 0.7720 - val_loss: 0.5286 - val_acc: 0.7987\n",
      "Epoch 93/100\n",
      "614/614 [==============================] - 0s 125us/step - loss: 0.4748 - acc: 0.7687 - val_loss: 0.5280 - val_acc: 0.7403\n",
      "Epoch 94/100\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.4760 - acc: 0.7655 - val_loss: 0.5239 - val_acc: 0.7597\n",
      "Epoch 95/100\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.4768 - acc: 0.7622 - val_loss: 0.5429 - val_acc: 0.7338\n",
      "Epoch 96/100\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.4723 - acc: 0.7801 - val_loss: 0.5264 - val_acc: 0.7597\n",
      "Epoch 97/100\n",
      "614/614 [==============================] - 0s 131us/step - loss: 0.4724 - acc: 0.7736 - val_loss: 0.5237 - val_acc: 0.7532\n",
      "Epoch 98/100\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.4709 - acc: 0.7687 - val_loss: 0.5316 - val_acc: 0.7403\n",
      "Epoch 99/100\n",
      "614/614 [==============================] - 0s 125us/step - loss: 0.4749 - acc: 0.7638 - val_loss: 0.5238 - val_acc: 0.7662\n",
      "Epoch 100/100\n",
      "614/614 [==============================] - 0s 156us/step - loss: 0.4731 - acc: 0.7801 - val_loss: 0.5161 - val_acc: 0.7792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6dcb94b00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit the model\n",
    "\n",
    "model.fit(X, Y, validation_split=0.2, nb_epoch=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 34us/step\n",
      "acc 0.78515625\n"
     ]
    }
   ],
   "source": [
    "## Evaluating the model\n",
    "\n",
    "score = model.evaluate(X,Y)\n",
    "print(model.metrics_names[1], score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING THE MANUAL VERIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## Creating model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compiling the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 154 samples\n",
      "Epoch 1/100\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.6900 - acc: 0.6289 - val_loss: 0.6838 - val_acc: 0.6948\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.6831 - acc: 0.6510 - val_loss: 0.6754 - val_acc: 0.6948\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.6771 - acc: 0.6510 - val_loss: 0.6700 - val_acc: 0.6948\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.6725 - acc: 0.6510 - val_loss: 0.6618 - val_acc: 0.6948\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.6680 - acc: 0.6510 - val_loss: 0.6561 - val_acc: 0.6948\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.6637 - acc: 0.6510 - val_loss: 0.6498 - val_acc: 0.6948\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 141us/step - loss: 0.6580 - acc: 0.6667 - val_loss: 0.6442 - val_acc: 0.6948\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 178us/step - loss: 0.6535 - acc: 0.6771 - val_loss: 0.6354 - val_acc: 0.7013\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.6430 - acc: 0.6875 - val_loss: 0.6255 - val_acc: 0.7792\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.6353 - acc: 0.6992 - val_loss: 0.6162 - val_acc: 0.7662\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.6373 - acc: 0.6836 - val_loss: 0.6192 - val_acc: 0.7403\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.6253 - acc: 0.7057 - val_loss: 0.6051 - val_acc: 0.7727\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 178us/step - loss: 0.6182 - acc: 0.7018 - val_loss: 0.5985 - val_acc: 0.7727\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 166us/step - loss: 0.6199 - acc: 0.6797 - val_loss: 0.5949 - val_acc: 0.7792\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 167us/step - loss: 0.6100 - acc: 0.7083 - val_loss: 0.5894 - val_acc: 0.7727\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.6050 - acc: 0.7122 - val_loss: 0.5884 - val_acc: 0.7338\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 145us/step - loss: 0.6010 - acc: 0.7109 - val_loss: 0.5797 - val_acc: 0.7532\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 137us/step - loss: 0.5961 - acc: 0.7161 - val_loss: 0.5756 - val_acc: 0.7597\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5934 - acc: 0.7214 - val_loss: 0.5730 - val_acc: 0.7727\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5918 - acc: 0.7148 - val_loss: 0.5764 - val_acc: 0.7403\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 141us/step - loss: 0.5878 - acc: 0.7188 - val_loss: 0.5671 - val_acc: 0.7662\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.5869 - acc: 0.7227 - val_loss: 0.5600 - val_acc: 0.7532\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.5849 - acc: 0.7148 - val_loss: 0.5593 - val_acc: 0.7532\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.5794 - acc: 0.7201 - val_loss: 0.5535 - val_acc: 0.7662\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 136us/step - loss: 0.5795 - acc: 0.7201 - val_loss: 0.5485 - val_acc: 0.7532\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 164us/step - loss: 0.5781 - acc: 0.7188 - val_loss: 0.5444 - val_acc: 0.7662\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.5718 - acc: 0.7201 - val_loss: 0.5421 - val_acc: 0.7597\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.5726 - acc: 0.7188 - val_loss: 0.5452 - val_acc: 0.7532\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.5679 - acc: 0.7292 - val_loss: 0.5366 - val_acc: 0.7662\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 181us/step - loss: 0.5646 - acc: 0.7357 - val_loss: 0.5410 - val_acc: 0.7532\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.5617 - acc: 0.7357 - val_loss: 0.5324 - val_acc: 0.7727\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 144us/step - loss: 0.5605 - acc: 0.7318 - val_loss: 0.5313 - val_acc: 0.7532\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.5576 - acc: 0.7279 - val_loss: 0.5281 - val_acc: 0.7597\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.5554 - acc: 0.7357 - val_loss: 0.5397 - val_acc: 0.7403\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.5617 - acc: 0.7148 - val_loss: 0.5286 - val_acc: 0.7792\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.5551 - acc: 0.7370 - val_loss: 0.5237 - val_acc: 0.7662\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5511 - acc: 0.7266 - val_loss: 0.5767 - val_acc: 0.7013\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 179us/step - loss: 0.5614 - acc: 0.7214 - val_loss: 0.5202 - val_acc: 0.7597\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.5495 - acc: 0.7383 - val_loss: 0.5271 - val_acc: 0.7532\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5471 - acc: 0.7318 - val_loss: 0.5227 - val_acc: 0.7597\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 146us/step - loss: 0.5467 - acc: 0.7383 - val_loss: 0.5100 - val_acc: 0.7727\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 136us/step - loss: 0.5426 - acc: 0.7422 - val_loss: 0.5066 - val_acc: 0.7727\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.5411 - acc: 0.7383 - val_loss: 0.5068 - val_acc: 0.7662\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 165us/step - loss: 0.5463 - acc: 0.7305 - val_loss: 0.5072 - val_acc: 0.7662\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.5443 - acc: 0.7461 - val_loss: 0.5000 - val_acc: 0.7857\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5425 - acc: 0.7422 - val_loss: 0.5139 - val_acc: 0.7532\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5362 - acc: 0.7487 - val_loss: 0.5048 - val_acc: 0.7662\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.5399 - acc: 0.7370 - val_loss: 0.5199 - val_acc: 0.7338\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5402 - acc: 0.7461 - val_loss: 0.5081 - val_acc: 0.7597\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5400 - acc: 0.7435 - val_loss: 0.5067 - val_acc: 0.7662\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5371 - acc: 0.7318 - val_loss: 0.4941 - val_acc: 0.7792\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5332 - acc: 0.7474 - val_loss: 0.5019 - val_acc: 0.7727\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.5327 - acc: 0.7461 - val_loss: 0.4907 - val_acc: 0.7727\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.5331 - acc: 0.7396 - val_loss: 0.5030 - val_acc: 0.7727\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 161us/step - loss: 0.5339 - acc: 0.7513 - val_loss: 0.4910 - val_acc: 0.7922\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.5301 - acc: 0.7500 - val_loss: 0.4909 - val_acc: 0.7792\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.5276 - acc: 0.7539 - val_loss: 0.4880 - val_acc: 0.7857\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5286 - acc: 0.7539 - val_loss: 0.4887 - val_acc: 0.7857\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.5314 - acc: 0.7500 - val_loss: 0.4870 - val_acc: 0.7792\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5278 - acc: 0.7526 - val_loss: 0.4865 - val_acc: 0.7792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 145us/step - loss: 0.5252 - acc: 0.7591 - val_loss: 0.4883 - val_acc: 0.7597\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5271 - acc: 0.7487 - val_loss: 0.4888 - val_acc: 0.7662\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5258 - acc: 0.7539 - val_loss: 0.4854 - val_acc: 0.7727\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5222 - acc: 0.7539 - val_loss: 0.5053 - val_acc: 0.7662\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5247 - acc: 0.7565 - val_loss: 0.4783 - val_acc: 0.7922\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5213 - acc: 0.7591 - val_loss: 0.4766 - val_acc: 0.8052\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5182 - acc: 0.7526 - val_loss: 0.5009 - val_acc: 0.7597\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5269 - acc: 0.7435 - val_loss: 0.4804 - val_acc: 0.7857\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5187 - acc: 0.7552 - val_loss: 0.4802 - val_acc: 0.7922\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.5218 - acc: 0.7591 - val_loss: 0.4784 - val_acc: 0.7727\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.5175 - acc: 0.7578 - val_loss: 0.4713 - val_acc: 0.7922\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.5149 - acc: 0.7578 - val_loss: 0.4939 - val_acc: 0.7532\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5200 - acc: 0.7578 - val_loss: 0.4943 - val_acc: 0.7662\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5191 - acc: 0.7552 - val_loss: 0.4777 - val_acc: 0.7727\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5178 - acc: 0.7578 - val_loss: 0.4705 - val_acc: 0.7922\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5174 - acc: 0.7656 - val_loss: 0.4712 - val_acc: 0.7857\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.5102 - acc: 0.7773 - val_loss: 0.4624 - val_acc: 0.8052\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 136us/step - loss: 0.5159 - acc: 0.7604 - val_loss: 0.4769 - val_acc: 0.7792\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5165 - acc: 0.7630 - val_loss: 0.4707 - val_acc: 0.7792\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.5074 - acc: 0.7682 - val_loss: 0.4896 - val_acc: 0.7727\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.5114 - acc: 0.7669 - val_loss: 0.4585 - val_acc: 0.7987\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 158us/step - loss: 0.5104 - acc: 0.7617 - val_loss: 0.4574 - val_acc: 0.7987\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.5061 - acc: 0.7617 - val_loss: 0.4647 - val_acc: 0.7987\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.5137 - acc: 0.7604 - val_loss: 0.4549 - val_acc: 0.8052\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 162us/step - loss: 0.5058 - acc: 0.7630 - val_loss: 0.4718 - val_acc: 0.7857\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 156us/step - loss: 0.5103 - acc: 0.7565 - val_loss: 0.4582 - val_acc: 0.8182\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 155us/step - loss: 0.5074 - acc: 0.7630 - val_loss: 0.4553 - val_acc: 0.7857\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.5057 - acc: 0.7591 - val_loss: 0.4511 - val_acc: 0.8182\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.5056 - acc: 0.7656 - val_loss: 0.4543 - val_acc: 0.8052\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 156us/step - loss: 0.5074 - acc: 0.7604 - val_loss: 0.4461 - val_acc: 0.8052\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 166us/step - loss: 0.5040 - acc: 0.7565 - val_loss: 0.4489 - val_acc: 0.8052\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 166us/step - loss: 0.5022 - acc: 0.7682 - val_loss: 0.4490 - val_acc: 0.8117\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 162us/step - loss: 0.5006 - acc: 0.7695 - val_loss: 0.4864 - val_acc: 0.7792\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.5190 - acc: 0.7448 - val_loss: 0.4492 - val_acc: 0.7922\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5029 - acc: 0.7604 - val_loss: 0.4520 - val_acc: 0.7922\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 215us/step - loss: 0.4999 - acc: 0.7617 - val_loss: 0.4505 - val_acc: 0.8052\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.4952 - acc: 0.7708 - val_loss: 0.4476 - val_acc: 0.8117\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.4981 - acc: 0.7643 - val_loss: 0.4427 - val_acc: 0.8052\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 138us/step - loss: 0.4991 - acc: 0.7643 - val_loss: 0.4419 - val_acc: 0.8052\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.4980 - acc: 0.7721 - val_loss: 0.4446 - val_acc: 0.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6d8827978>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit the model\n",
    "\n",
    "model.fit(X, Y, validation_data=(X_test, Y_test), nb_epoch=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 39us/step\n",
      "acc 0.766927083333\n"
     ]
    }
   ],
   "source": [
    "## Evaluating the model\n",
    "\n",
    "score = model.evaluate(X,Y)\n",
    "print(model.metrics_names[1], score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUAL K-FOLD CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gold standard for machine learning model evaluation is k-fold cross validation.\n",
    "\n",
    "Cross validation is often not used in evaluation of deep learning model as of the greater computation cost.\n",
    "\n",
    "It provides the robust estimate of the performance of a model on unseen data. It does this by spliting the training dataset into k subsets and takes turns training models on all subsets except one which is held out and evaluating model performance on the held out validation datasets this process is repeated untill all subsets are given an opportunity to be held out validation set. The performance is then averaged across all models that are created.\n",
    "\n",
    "In the below example we used **StatifiedFold** class. In this the Machine learning datasets are splited into folds. The folds are stratified meaning that the algorithm attempts to balance the number of instances of class in each folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1].values\n",
    "Y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscore = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 72.7272729595\n",
      "acc 81.818181973\n",
      "acc 67.5324678421\n",
      "acc 66.2337665434\n",
      "acc 71.428571893\n",
      "acc 67.5324678421\n",
      "acc 77.9220780769\n",
      "acc 75.3246754795\n",
      "acc 73.6842102126\n",
      "acc 76.3157894737\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, Y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "    model.add(Dense(8, init='uniform', activation='relu'))\n",
    "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X[train], Y[train], nb_epoch=100, batch_size=10, verbose=0)\n",
    "    \n",
    "    score = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    \n",
    "    print(model.metrics_names[1], score[1]*100)\n",
    "    \n",
    "    cvscore.append(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.1775463236 4.91821086008\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cvscore), np.std(cvscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
